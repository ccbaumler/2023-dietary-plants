import os

configfile: "config.yaml"

group = config.get("group")
indir = [os.path.join("input", dir_name) for dir_name in group]

print(indir)

SAMPLES_DICT = {}
for path in indir:
    for (dirpath, dirnames, filenames) in os.walk(path):
        dir_name = os.path.basename(dirpath)
        SAMPLES_DICT[dir_name] = [filename.split('_')[0] for filename in filenames]#[:5]
        break

list_all_inputs = [ 
    expand(
        f"output/{group_id}/{{db}}/cmon_name_annot/{{db}}.{sample_id}.{{k}}.annot.gather.csv",  db=config["dbs"], k=config["k_size"]
        ) 
    for group_id, sample_list in SAMPLES_DICT.items() for sample_id in sample_list ]
#
#lambda wildcards: printf(*SAMPLES_DICT[wildcards.group])
#lambda wildcards: print((f"output/{group}/{{db}}/cmon_name_annot/{{db}}.{{sample}}.{{k}}.annot.gather.csv",  db=config["dbs"] , sample=SAMPLES_DICT[wildcards.group], k=config["k_size"]))
##rule_all_inputs 

#def extract_samples():
#    input_directory = "input/"+config["group"]
#    input_files = os.listdir(input_directory)
#    # Extract sample names from the filenames and create the SAMPLES list
#    SAMPLES = []
#    for filename in input_files:
#        if filename.endswith("_1.fastq.gz"):
#            sample_name = filename.replace("_1.fastq.gz", "")
#            SAMPLES.append(sample_name)
#    return SAMPLES
#
# Function to load SAMPLES list from pickle file
#def load_samples():
#    with open("sample_list.pkl", "rb") as f:
#        return pickle.load(f)

#SAMPLES = extract_samples()

# Another method for ustilizing a config file in snakemake to the fullest
#def get_wildcards(wildcards):
#    print(config["dbs"][wildcards.db])
#    print(config["k_size"][wildcards.k])
#get_wildcards(wildcards)

#def name_scheme():
#    if config["db"] == './../Sketched-db/db.crop-plant-entrez.ref.sig.zip':
#        return config["group"]+"."+config["k"]+"."+"crop_genome"
#    else:
#        return config["group"]+"."+config["k"]+"."+"genome"


#dir_name = name_scheme()
#SAMPLES = extract_samples()

#SAMPLES=SAMPLES[:5]
#print(SAMPLES)
# test rule
#rule test:
#    params:
#        dir_name =dir_name,
#        another = SAMPLES,
#        k = config['k'],
#        group= config["group"]
#    shell:
#        """
#        echo "{params.k},{params.group}"
#        echo "{params.dir_name} and {params.another}"
#        
#        """

# SNAKEMAKE RULES
rule all:
   input:
        list_all_inputs
        #expand("output/" + config["group"] + "/{db}/cmon_name_annot/{db}.{sample}.{k}.annot.gather.csv",  db=config["dbs"] ,sample=SAMPLES, k=config["k_size"])


# Rule for running Sourmash sketch
rule run_sourmash_sketch:
    input:
        r1="input/{group}/{sample}_1.fastq.gz",
        r2="input/{group}/{sample}_2.fastq.gz"
    output:
        "output/{group}/sketches/{sample}.sig.zip"
    conda:
        "sourmash.yml"
#    benchmark:
#        repeat("benchmarks/run_sourmash_sketch.{group}.{sample}.tsv", 5)
    resources:
        mem_mb=85*5,
        runtime= lambda wildcards, attempt: 125 / 60 * 5
    shell:
        "sourmash sketch dna -p scaled=100,k=21,k=31,k=51,abund {input.r1} {input.r2} --name '{wildcards.sample}' -o {output}"

# Rule for running Sourmash gather
rule run_sourmash_gather:
    input:
        "output/{group}/sketches/{sample}.sig.zip"
    output:
        #"output/prefetch/{sample}.prefetch.csv" #{db}.{ksize}.{sample}
        "output/{group}/{db}/gather/{db}.{sample}.{k}.gather.csv"
    conda:
        "sourmash.yml"
    params:
        # Access the file name instead of the assigned name
        db_file = lambda wildcards:config["dbs"][wildcards.db],
        #k = config["k"]
#    benchmark:
#        repeat("benchmarks/run_sourmash_gather.{group}.{db}.{sample}.{k}.tsv", 5)
    resources:
        mem_mb=205*5,
        runtime= lambda wildcards, attempt: 365 / 60 * 5
    shell:
        #"sourmash prefetch {input} db.trnL-entrez-ref.fasta.sig --dna --ksize 51 --threshold-bp 0 -o {output}" #save prefetch results
        "sourmash gather {input} {params.db_file} --threshold-bp 0 -k {wildcards.k} -o {output}" 

# Rule for performing inner join with common_names.csv
rule perform_inner_join:
    input:
       "output/{group}/{db}/gather/{db}.{sample}.{k}.gather.csv" ,
    output:
       "output/{group}/{db}/cmon_name_annot/{db}.{sample}.{k}.annot.gather.csv" #{db.{ksize}.{sample}.common.csv
#    benchmark:
#        repeat("benchmarks/perform_inner_join.{group}.{db}.{sample}.{k}.tsv", 5)
    resources:
        mem_mb=75*5,
        runtime= lambda wildcards, attempt: 25 / 60 * 5
    shell:
       "python join_common_name_dbs.py {input} {output}"

#list_all_inputs = [ expand(f"output/{group_id}/{{db}}/cmon_name_annot/{{db}}.{sample_id}{{k}}.annot.gather.csv",  db=config["dbs"], k=config["k_size"]) for group_id, sample_id in SAMPLES_DICT.items() ]
#print(list_all_inputs)
