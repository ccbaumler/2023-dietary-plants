import os

configfile: "config.yaml"

def extract_samples():
    input_directory = "input/"+config["group"]
    input_files = os.listdir(input_directory)
    # Extract sample names from the filenames and create the SAMPLES list
    SAMPLES = []
    for filename in input_files:
        if filename.endswith("_1.fastq.gz"):
            sample_name = filename.replace("_1.fastq.gz", "")
            SAMPLES.append(sample_name)
    return SAMPLES

SAMPLES = extract_samples()

def make_input_list():
    input_list =[]
    for db,filepath in config["dbs"].items():
        if db== 'trnl':
            tt = expand("output/" + config["group"] + "/{db}.{scale}/cmon_name_annot/{sample}.{k}.annot.gather.csv",  db=db ,sample=SAMPLES, k=config["k_size"], scale=100)
            input_list.extend(tt)
        else:
            tt= expand("output/" + config["group"] + "/{db}.{scale}/cmon_name_annot/{sample}.{k}.annot.gather.csv",  db=db ,sample=SAMPLES, k=config["k_size"], scale=100)
            input_list.extend(tt)
    return input_list

print(make_input_list())
print(len(make_input_list()))


# SNAKEMAKE RULES
rule all:
   input:
        make_input_list()

# Rule for running Sourmash sketch
rule run_sourmash_sketch:
    input:
        r1="input/" + config["group"] + "/{sample}_1.fastq.gz",
        r2="input/" + config["group"] + "/{sample}_2.fastq.gz"
    output:
        "output/" + config["group"] + "/sketches/{sample}.sig.zip"
    #conda:
    #   "sourmash.yml"
    shell:
        "sourmash sketch dna -p scaled=100,k=21,k=31,k=51,abund {input.r1} {input.r2} --name '{wildcards.sample}' -o {output}"

# Rule for running Sourmash gather
rule run_sourmash_gather:
    input:
        "output/" + config["group"] + "/sketches/{sample}.sig.zip"
    output:
        gather_csv ="output/" + config["group"] +"/{db}.{scale}/gather/{sample}.{k}.gather.csv",
        prefetch_sigs= "output/" + config["group"] +"/{db}.{scale}/gather_ext/{sample}.{k}.prefetch.sig",
        gather_matches = "output/" + config["group"] +"/{db}.{scale}/gather_ext/{sample}.{k}.gather.sig",
        prefetch_csv = "output/" + config["group"] +"/{db}.{scale}/gather_ext/{sample}.{k}.prefetch.csv",
    #conda:
    #   "sourmash.yml"
    params:
        # Access the file name instead of the assigned name
        db_file = lambda wildcards:config["dbs"][wildcards.db],
        #k = config["k"]
    shell:
        #"sourmash prefetch {input} db..{scale}trnL-entrez-ref.fasta.sig --dna --ksize 51 --threshold-bp 0 -o {output}" #save prefetch results
        "sourmash gather {input} {params.db_file} --scaled {wildcards.scale} --threshold-bp 0 -k {wildcards.k} --save-matches {output.gather_matches} --save-prefetch {output.prefetch_sigs} --save-prefetch-csv {output.prefetch_csv} -o {output.gather_csv}" 

# Rule for performing inner join with common_names.csv
rule perform_inner_join:
    input:
       "output/" + config["group"] + "/{db}.{scale}/gather/{sample}.{k}.gather.csv" ,
    output:
       "output/" + config["group"] + "/{db}.{scale}/cmon_name_annot/{sample}.{k}.annot.gather.csv" #{db..{scale}{ksize}.{sample}.common.csv
    shell:
       "python join_common_name_dbs.py {input} {output}"

