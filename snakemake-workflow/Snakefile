import os
#import pickle

configfile: "config.yaml"

def extract_samples():
    input_directory = "input/"+config["group"]
    input_files = os.listdir(input_directory)
    # Extract sample names from the filenames and create the SAMPLES list
    SAMPLES = []
    for filename in input_files:
        if filename.endswith("_1.fastq.gz"):
            sample_name = filename.replace("_1.fastq.gz", "")
            SAMPLES.append(sample_name)
    return SAMPLES

# Function to load SAMPLES list from pickle file
#def load_samples():
#    with open("sample_list.pkl", "rb") as f:
#        return pickle.load(f)

#SAMPLES = extract_samples()

# Another method for ustilizing a config file in snakemake to the fullest
def get_wildcards(wildcards):
    return config["dbs"][wildcards.db]
    return config["k_size"][wildcards.k]

#def name_scheme():
#    if config["db"] == './../Sketched-db/db.crop-plant-entrez.ref.sig.zip':
#        return config["group"]+"."+config["k"]+"."+"crop_genome"
#    else:
#        return config["group"]+"."+config["k"]+"."+"genome"


#dir_name = name_scheme()
SAMPLES = extract_samples()

SAMPLES=SAMPLES[:5]
print(SAMPLES)
# test rule
#rule test:
#    params:
#        dir_name =dir_name,
#        another = SAMPLES,
#        k = config['k'],
#        group= config["group"]
#    shell:
#        """
#        echo "{params.k},{params.group}"
#        echo "{params.dir_name} and {params.another}"
#        
#        """

# SNAKEMAKE RULES
rule all:
   input:
        expand("output/" + config["group"] + "/{db}/cmon_name_annot/{db}.{sample}.{k}.annot.gather.csv",  db=config["dbs"] ,sample=SAMPLES, k=config["k_size"])


# Rule for running Sourmash sketch
rule run_sourmash_sketch:
    input:
        r1="input/" + config["group"] + "/{sample}_1.fastq.gz",
        r2="input/" + config["group"] + "/{sample}_2.fastq.gz"
    output:
        "output/" + config["group"] + "/sketches/{sample}.sig.zip"
    conda:
        "sourmash.yml"
    benchmark:
        "benchmarks/run_sourmash_sketch." + config["group"] + ".{sample}.tsv"
    shell:
        "sourmash sketch dna -p scaled=100,k=21,k=31,k=51,abund {input.r1} {input.r2} --name '{wildcards.sample}' -o {output}"

# Rule for running Sourmash gather
rule run_sourmash_gather:
    input:
        "output/" + config["group"] + "/sketches/{sample}.sig.zip"
    output:
        #"output/prefetch/{sample}.prefetch.csv" #{db}.{ksize}.{sample}
        "output/" + config["group"] + "/{db}/gather/{db}.{sample}.{k}.gather.csv"
    conda:
        "sourmash.yml"
    params:
        # Access the file name instead of the assigned name
        db_file = lambda wildcards:config["dbs"][wildcards.db],
        #k = config["k"]
    benchmark:
        "benchmarks/run_sourmash_gather." + config["group"] + ".{db}.{sample}.{k}.tsv"
    shell:
        #"sourmash prefetch {input} db.trnL-entrez-ref.fasta.sig --dna --ksize 51 --threshold-bp 0 -o {output}" #save prefetch results
        "sourmash gather {input} {params.db_file} --threshold-bp 0 -k {wildcards.k} -o {output}" 

# Rule for performing inner join with common_names.csv
rule perform_inner_join:
    input:
       "output/" + config["group"] + "/{db}/gather/{db}.{sample}.{k}.gather.csv" ,
    output:
       "output/" + config["group"] + "/{db}/cmon_name_annot/{db}.{sample}.{k}.annot.gather.csv" #{db.{ksize}.{sample}.common.csv
    benchmark:
        "benchmarks/perform_inner_join." + config["group"] + ".{db}.{sample}.{k}.tsv"
    shell:
       "python join_common_name_dbs.py {input} {output}"

