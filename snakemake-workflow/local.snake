import os

# Setting up the input and variables
# Use a config file
configfile: "config.yaml"

# Get group values for input file list
#contaminant = config.get("contaminant")
group = config.get("group")

indir = [os.path.join("input", dir_name) for dir_name in group]

print(indir)

SAMPLES_DICT = {}
for path in indir:
    for (dirpath, dirnames, filenames) in os.walk(path):
        dir_name = os.path.basename(dirpath)
        SAMPLES_DICT[dir_name] = [filename.split('_')[0] for filename in filenames][:5]
        break

list_all_inputs = [ 
    expand(
        f"output/{group_id}/{{db}}.{{scale}}/cmon_name_annot/{sample_id}.{{k}}.annot.gather.csv",  db=config["dbs"], k=config["k_size"], scale=config["scale"]
        ) 
    for group_id, sample_list in SAMPLES_DICT.items() for sample_id in sample_list ]

# SNAKEMAKE RULES
rule all:
   input:
        list_all_inputs

#
# Change sketch rule to sketchall plugin!
#

rule run_sourmash_sketch:
    input:
        r1="input/{group}/{sample}_1.fastq.gz",
        r2="input/{group}/{sample}_2.fastq.gz"
    output:
        "output/{group}/sketches/{sample}.{scale}.sig.zip"
    conda:
        "sourmash.yml"
    resources:
        mem_mb = lambda wildcards, attempt: 85 * attempt,
        runtime = lambda wildcards, attempt: 125 / 60 * attempt
    params:
        k_list = lambda wildcards: ",".join([f"k={k}" for k in config["k_size"]])
    benchmark:
        repeat('benchmarks/run_sourmash_sketch.{group}.{sample}.{scale}.tsv', 5)
    shell:"""
        sourmash sketch dna -p scaled={wildcards.scale},{params.k_list},abund {input.r1} {input.r1} --name '{wildcards.sample}' -o {output}
    """

#
# Change prefetch and gather to fastmultigather!
#

rule run_sourmash_prefetch:
    input:
        "output/{group}/sketches/{sample}.{scale}.sig.zip"
    output:
        query_matching_sigs = "output/{group}/{db}.{scale}/hash_matches/{sample}.{k}.query-matches.sig",
        db_matching_sigs = "output/{group}/{db}.{scale}/gather_ext/{sample}.{k}.db-matches.sig",
        prefetch_csv = "output/{group}/{db}.{scale}/gather_ext/{sample}.{k}.prefetch.csv",
    conda:
        "sourmash.yml"
    params:
        # Access the file name instead of the assigned name
        db_file = lambda wildcards:config["dbs"][wildcards.db],
#    resources:
#        mem_mb= lambda wildcards, attempt: 205 * attempt,
#        runtime= lambda wildcards, attempt: 365 / 60 * attempt
    benchmark:
        repeat('benchmarks/run_sourmash_gather.{k}.{sample}.{db}.{scale}.{group}.tsv', 5)
    shell:"""
        sourmash prefetch {input} {params.db_file} --scaled {wildcards.scale} --dna --ksize {wildcards.k} --threshold-bp 0 --save-matching-hashes {output.query_matching_sigs} --save-matches {output.db_matching_sigs} -o {output.prefetch_csv}
    """

rule run_sourmash_gather:
    input:
        query_matching_sigs = "output/{group}/{db}.{scale}/hash_matches/{sample}.{k}.query-matches.sig",
        db_matching_sigs = "output/{group}/{db}.{scale}/gather_ext/{sample}.{k}.db-matches.sig",
    output:
        gather_matches = "output/{group}/{db}.{scale}/gather_ext/{sample}.{k}.gather.sig",
        gather_csv =touch("output/{group}/{db}.{scale}/gather/{sample}.{k}.gather.csv"),
    conda:
        "sourmash.yml"
#    resources:
#        mem_mb= lambda wildcards, attempt: 205 * attempt,
#        runtime= lambda wildcards, attempt: 365 / 60 * attempt
    benchmark:
        repeat('benchmarks/run_sourmash_gather.{k}.{sample}.{db}.{scale}.{group}.tsv', 5)
    shell:"""
        sourmash gather {input.query_matching_sigs} {input.db_matching_sigs} --scaled {wildcards.scale} --threshold-bp 0 -k {wildcards.k} --save-matches {output.gather_matches} -o {output.gather_csv}
    """

# Rule for performing inner join with common_names.csv
rule perform_inner_join:
    input:
       "output/{group}/{db}.{scale}/gather/{sample}.{k}.gather.csv" ,
    output:
       "output/{group}/{db}.{scale}/cmon_name_annot/{sample}.{k}.annot.gather.csv"
    resources:
        mem_mb= lambda wildcards, attempt: 75 * attempt,
        runtime= lambda wildcards, attempt: 25 / 60 * attempt
    benchmark:
        repeat('benchmarks/perform_inner_join.{k}.{sample}.{db}.{scale}.{group}.tsv', 5)
    shell:"""
       python join_common_name_dbs.py {input} {output}
    """
